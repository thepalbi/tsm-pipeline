## First attempt to run the whole pipeline and get scores

Picking tainted path as query. Picking a set of 20 projects to use, from the atm-databases.

```
18F/share
2019SP93022/bmaharishi-hireadda-de95914d54ff
3drepo/3drepo.io
3dsNode/3dsNode
4front/cli
AFTERCARE/ME-weather
ASCOT/dashboardjs
AdguardTeam/Scriptlets
Aerods/cubs
Alfarie/LinkitSmart
Azure/Samples-SpeechToText-WebSockets-Javascript
Azure/ibex-dashboard
Binomi0/crm-backoffice-api
BoredHackerBlog/runthelabs
CartoDB/grainstore
CatalystCode/ibex-dashboard-apollo-graphql
ChaituVR/back-editor
ChaituVR/fileAbstract
ChromeDevTools/devtools-frontend
DCKT/localhost-now
```

From this list, and filtering found repos with over 50% of JS, the list stays to:

```
18F/share/6578b16d9525ee23256ea0fcde5c5f52f81cc545
3dsNode/3dsNode/61bc3d0a9fce46155e042bd841825f325e648b43
4front/cli/47523f395427028fe16268a3e686ebfa40ceeca8
ASCOT/dashboardjs/352a8b6710d6f2ddfd42ddfa0266af65c9c23ebe
AdguardTeam/Scriptlets/00f558aa7e2c106cb4746ff6561925cf6cabc8cc
Alfarie/LinkitSmart/3383ae864430f686b5156681564a88bd94f70100
BoredHackerBlog/runthelabs/8f859ecafbfa8e0a9984d9c66b8c691146ecee3d
CartoDB/grainstore/a28f8c300b9067ccc94773dd041d1ce2e0ac39a4
DCKT/localhost-now/30b004c7f145d677df8800a106c2edc982313995
```

Writing that down that list to a file, and caching DBS with:
```
python -m database.cli --list /tmp/list --cache-root /tesis/dbs/ --cli-version 2.10.5
```

Now, from the first 50 entries in TaintedPath.csv, picked the ones with data and over 65% of JS lines (22 results):
```
// Train - 15
18F/share/6578b16d9525ee23256ea0fcde5c5f52f81cc545
3dsNode/3dsNode/61bc3d0a9fce46155e042bd841825f325e648b43
4front/cli/47523f395427028fe16268a3e686ebfa40ceeca8
ASCOT/dashboardjs/352a8b6710d6f2ddfd42ddfa0266af65c9c23ebe
AdguardTeam/Scriptlets/00f558aa7e2c106cb4746ff6561925cf6cabc8cc
Alfarie/LinkitSmart/3383ae864430f686b5156681564a88bd94f70100
CartoDB/grainstore/a28f8c300b9067ccc94773dd041d1ce2e0ac39a4
DCKT/localhost-now/30b004c7f145d677df8800a106c2edc982313995
DanielGomez2016/MemotraficoV2/a4bdd2ba432e90dbf5481bb87cf3492c9a750e02
DimiMikadze/react-native-game/e6dc55aaf02e30bd04bd1e7da826ed3d96e996ee
DoubleSpout/threadAndPackage/78bde22b483004e28e3ed50b5db36e66b8e0afd7
Ealenn/Echo-Server/3ad29a4d210eafe7652229d69ed542f863ed0aee
Espacorede/WikiStats/b0c9808b006ac720f2627cf55997e30597e2dc92
Esri/esri-gnip-loader/098f9a4e8aa32edd0b2c7e6aac632df5de489a25
FremyCompany/css-grid-polyfill/db9a0451ae3c06475d31e10adf2547bd3d34b6f4

// Evaluation - 7
FurutaTakuto/infoVis2017/7b7aa8999b4233eb2b9e5fc7d3ba6488b80ed141
GitbookIO/gitbook/6c6ef7f4af32a2977e44dd23d3feb6ebf28970f4
GoogleChromeLabs/sw-precache/b202ca04fe87555d7fe9ca338f87fbcf76812c39
GuiWukai/first_node/7b60c5fbfb414db8ada5baa100ff0b5364132dc9
GuildCrafts/floworky/f2b489cd6a49ed444e8e52d0d5fbf7d738d6e21e
IBM/predictive-market-using-arria/2edef3d8ea89531737272e4fae88985dff9b6dd5
IonicaBizau/statique/df33233318d95e3902bb9d6962ecfc44fde9d4bd
```

Caching them with the same command as above:
```
# For running old queries, in learning
python -m database.cli --list /tmp/list --cache-root /tesis/dbs/ --cli-version 2.5.2
# For running new queries, in evaluation
python -m database.cli --list /tmp/list --cache-root /tesis/dbs/ --cli-version 2.10.5
```

Selected results dir: `/tesis/tmp/results/fmu7UomymbomImzU`
To run pipeline over training projects
```
./scripts/docker_run.sh /bigtmp/list.txt /tesis/tmp/results/fmu7UomymbomImzU

FAIL: Error when executing codeql, stderr: Running queries.
Did not find any ML models.
Compiling query plan for /ql/tsm/Path/Known-Path.ql.
WARNING: A graph query must define the @id property. (/ql/tsm/Path/Known-Path.ql:1,1-3,4)
WARNING: A graph query must select an edge relation. (/ql/tsm/Path/Known-Path.ql:1,1-3,4)
A fatal error occurred: The CodeQL database is not compatible with a QL library referenced by the query you are trying to run.
```
The failure is probably caused because the TSM learning libraries (not evaluation) do not support new CLI's, probably because of breaking changes. Trying to generate dbs both for the new version of the CLI (2.10.5) and old (2.5.2). Then will execute the learning pipeline with the old CLI.

Trying full run again, now with 2.5.2 dbs:
```
./scripts/docker_run.sh /bigtmp/list.txt /tesis/tmp/results/fmu7UomymbomImzU
```

Ran successfully, and captured in `/tesis/tmp/results/fmu7UomymbomImzU/averaged-results.txt` the averaged learned results. Some notes from the run:
- Need to run the command with nohup and in background
- Need to add some logging, so even though is running on background I can track the run
- CPU usage was low and also memory during runs. Need to parallelize.
    - Maybe use Airflow for this, and somehow pass as paramter the results directory
    - Review the `combinescores.py`, it's the part I trust the less

## Next: Evaluate the results
<mark>TODO: For reading the learned repr scores in the Boosted query run, use the functionality to read from CSV facts</mark>

## Some notes on how to use external predicates

An external predicate is one that cannot be bound to a class, and is annotated with the `external` decorator. For example:
```
external float testGetReprScores(string repr, string t);
```
When evaluating a query consuming this predicate, the facts to which is associated are injected though a CSV file with the following shape (for the example above):
```csv
"repr","sink",5
"repr2","source",10
```
Note that in the order of the columns, it starts from the leftmost argument to the right, and lastly, the result.

Even if you scope the external predicate into a `module`, it will be referred just with the predicate name. For example, when injecting the values for this predicate, the following CLI argument has to be added: `--external=testGetReprScores=test.csv`.

**18-09-2022**

Modified the `scripts.evaluate` script to accept a DBs list, and run both the evaluation query and decoding over the list.
```
python -m scripts.evaluate --codeql-source worse --dbs /tesis/tmp/results/fmu7UomymbomImzU/evaluate.txt --cache-root /tesis/dbs --output /tesis/tmp/results/fmu7UomymbomImzU/worse

# Running the same with default query run extra args (2 threads, 6GB memory) and a pool of two workers
python -m scripts.evaluate --codeql-source v0 --dbs /tesis/tmp/results/fmu7UomymbomImzU/evaluate.txt --cache-root /tesis/dbs --output /tesis/tmp/results/fmu7UomymbomImzU/v0
```

Corrió mucho más rápido con `Pool` y las opciones de threading!

Now, solvng the TODO above, I changed the `getReprScore` pred to be external, and `combinescores.py` to generate the necessary facts for that to run. Running with that now:
```
python -m scripts.evaluate --codeql-source worse --dbs /tesis/tmp/results/fmu7UomymbomImzU/evaluate.txt --cache-root /tesis/dbs --output /tesis/tmp/results/fmu7UomymbomImzU/worse --boost-results /tesis/tmp/results/fmu7UomymbomImzU/averaged-results.csv
```

## Notes

- Gitub PAT token for public repos: `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`
- Using this to generate random string: `openssl rand -base64 12`
---
title: 29-12-2022
publish_date: 2022-12-29
---
La idea de hoy es dejar el training de SQL corriendo. Se me ocurrió la idea de armar los experimentos en forma de librería, de forma de poder dejar escrito como un archivo de python (o un notebook), los experimentos que corro. Habría que ver qué tal fácil es dejar corriendo un server de jupyterlab, y ver si puede conectarse con el docker daemon.

Primero, a correr SQL:

```
nohup ./scripts/docker_run.sh \
    /tesis/repos/tsm-pipeline/experiments/tesis/atm_sql_train.txt \
    /tesis/tmp/results/sql_top_atm/ \
    "sql_top_atm" Sql SqlInjectionWorse 2> /tesis/sql_top_atm.log &
```

No boost, terrible. Porbando con NoSQL que hay mas cantidad: `/tesis/repos/tsm-pipeline/experiments/tesis/atm_nosql_top100.txt`

Primero armo los splits
```
python -m scripts.split --name atm_nosql_top100 --entries-file /tesis/repos/tsm-pipeline/experiments/tesis/atm_nosql_top100.txt --train-size .7
```

Cacheo todas las dbs:
```
python -m database.cli --list /tesis/repos/tsm-pipeline/experiments/tesis/atm_nosql_top100.txt --cache-root /tesis/dbs/ --cli-version 2.5.2 --parallel --thread-count=8
python -m database.cli --list /tesis/repos/tsm-pipeline/experiments/tesis/atm_nosql_top100.txt --cache-root /tesis/dbs/ --cli-version 2.10.5 --parallel --thread-count=8
```
entrenando:
```
nohup ./scripts/docker_run.sh \
    /tesis/repos/tsm-pipeline/experiments/tesis/atm_nosql_top100_train.txt \
    /tesis/tmp/results/atm_nosql_top100/ \
    "atm_nosql_top100" NoSql NosqlInjectionWorse &> /tesis/atm_nosql_top100.log &
```


{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8636f14c-b682-4e31-b5e9-f2d636279beb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e73a2d6e-002c-4755-8ba9-f0e7369f8992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from experiments.all import train_and_evaluate\n",
    "from tsm.configuration import TSMConfigParser\n",
    "import docker\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# load configuration\n",
    "config = TSMConfigParser()\n",
    "config.read(\"/home/pablo/tesis/tsm-pipeline/code/configs/pablo-bestia.cfg\")\n",
    "config.check()\n",
    "docker_client = docker.from_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "229dde66-065f-4d8e-b135-c1e16a3f49b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scripts.docker import read_dbs_dataset\n",
    "from numpy.random import RandomState\n",
    "from random import sample\n",
    "\n",
    "nosql_dbs = read_dbs_dataset(\"/home/pablo/tesis/tsm-pipeline/experiments/datasets/nosql_1.txt\")\n",
    "# Using a fixed random state to have reproducible results\n",
    "rand = RandomState(seed=5)\n",
    "\n",
    "sample_100 = rand.choice(nosql_dbs, size=100, replace=False)\n",
    "sample_20 = rand.choice(nosql_dbs, size=20, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32a9893b-d49b-4d15-8f90-a82190c8ba15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:experiments.all:train_and_evaluate with train size 100, test size 11\n",
      "INFO:experiments.all:Running training\n",
      "INFO:scripts.docker:creating /home/pablo/dev-results/nosql-perf-experiment-100-run1 dir. Omitting error if already existing\n",
      "INFO:scripts.docker:creating /tmp/log dir. Omitting error if already existing\n",
      "INFO:scripts.docker:running at container 75d12eb47261bef328f31587e134ed2173292786e213dc3617ebff8be28bc5e8. Use `docker logs 75d12eb47261bef328f31587e134ed2173292786e213dc3617ebff8be28bc5e8 --tail 10 --follow` to follow progress\n",
      "INFO:scripts.docker:running combine scores\n",
      "INFO:misc.combinescores:globbing folder: /home/pablo/dev-results/nosql-perf-experiment-100-run1/*/reprScores.txt\n",
      "INFO:misc.combinescores:working on 59 reprScores files\n",
      "INFO:experiments.all:Running worse evaluation\n",
      "INFO:scripts.evaluate:creating /home/pablo/dev-results/nosql-perf-experiment-100-run1/worse dir. Omitting error if already existing\n",
      "INFO:scripts.evaluate:Starting processing with 4 processes\n",
      "INFO:scripts.evaluate:Evaluating sessio - mvrekisteri\n",
      "INFO:scripts.evaluate:Evaluating lisanoetzel - rate-admin\n",
      "INFO:scripts.evaluate:Evaluating Gingernaut - Robot-Lawyer\n",
      "INFO:scripts.evaluate:Evaluating athongintel - drawlove-android\n",
      "INFO:scripts.evaluate:Evaluating capoxix - roamy\n",
      "INFO:scripts.evaluate:Evaluating itemsapi - itemsapi\n",
      "INFO:scripts.evaluate:Evaluating unbug - ddms\n",
      "INFO:scripts.evaluate:Evaluating Tencent - westore\n",
      "INFO:scripts.evaluate:Evaluating tutley - chive\n",
      "INFO:scripts.evaluate:Evaluating Azure - blackbelt-aks-hackfest\n",
      "INFO:scripts.evaluate:Evaluating theGioiLa - File-Management-\n",
      "INFO:experiments.all:Running boosted evaluation\n",
      "INFO:scripts.evaluate:creating /home/pablo/dev-results/nosql-perf-experiment-100-run1/boosted dir. Omitting error if already existing\n",
      "INFO:scripts.evaluate:Starting processing with 4 processes\n",
      "INFO:scripts.evaluate:Evaluating Gingernaut - Robot-Lawyer\n",
      "INFO:scripts.evaluate:Evaluating athongintel - drawlove-android\n",
      "INFO:scripts.evaluate:Evaluating lisanoetzel - rate-admin\n",
      "INFO:scripts.evaluate:Evaluating sessio - mvrekisteri\n",
      "INFO:scripts.evaluate:Evaluating itemsapi - itemsapi\n",
      "INFO:scripts.evaluate:Evaluating Tencent - westore\n",
      "INFO:scripts.evaluate:Evaluating unbug - ddms\n",
      "INFO:scripts.evaluate:Evaluating capoxix - roamy\n",
      "INFO:scripts.evaluate:Evaluating tutley - chive\n",
      "INFO:scripts.evaluate:Evaluating Azure - blackbelt-aks-hackfest\n",
      "INFO:scripts.evaluate:Evaluating theGioiLa - File-Management-\n",
      "INFO:experiments.all:Running v0 evaluation\n",
      "INFO:scripts.evaluate:creating /home/pablo/dev-results/nosql-perf-experiment-100-run1/v0 dir. Omitting error if already existing\n",
      "INFO:scripts.evaluate:Starting processing with 4 processes\n",
      "INFO:scripts.evaluate:Evaluating sessio - mvrekisteri\n",
      "INFO:scripts.evaluate:Evaluating lisanoetzel - rate-admin\n",
      "INFO:scripts.evaluate:Evaluating itemsapi - itemsapi\n",
      "INFO:scripts.evaluate:Evaluating athongintel - drawlove-android\n",
      "INFO:scripts.evaluate:Evaluating Gingernaut - Robot-Lawyer\n",
      "INFO:scripts.evaluate:Evaluating capoxix - roamy\n",
      "INFO:scripts.evaluate:Evaluating Tencent - westore\n",
      "INFO:scripts.evaluate:Evaluating unbug - ddms\n",
      "INFO:scripts.evaluate:Evaluating tutley - chive\n",
      "INFO:scripts.evaluate:Evaluating Azure - blackbelt-aks-hackfest\n",
      "INFO:scripts.evaluate:Evaluating theGioiLa - File-Management-\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>alerts to recover (atr)</th>\n",
       "      <th>alerts recovered</th>\n",
       "      <th>suprious alerts</th>\n",
       "      <th>projects with atr</th>\n",
       "      <th>avg atr per proj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.064</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>232</td>\n",
       "      <td>5</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall  accuracy  alerts to recover (atr)  alerts recovered  \\\n",
       "0   0.064516  0.888889     0.064                       18                16   \n",
       "\n",
       "   suprious alerts  projects with atr  avg atr per proj  \n",
       "0              232                  5               3.6  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdir = \"/home/pablo/dev-results/nosql-perf-experiment-100-run1\"\n",
    "\n",
    "results = train_and_evaluate(\n",
    "    config=config,\n",
    "    results_dir=outdir,\n",
    "    query_type=\"nosql\",\n",
    "    train=list(sample_100),\n",
    "    test=list(set(sample_20) - set(sample_100)),\n",
    "    docker_client=docker_client,\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042eb0de-48ef-42d4-8970-a2fe32b430b1",
   "metadata": {},
   "source": [
    "## mismos experimentos de perf con xss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ceba4afe-6ca9-4ee5-8e9c-1c43fc46aa0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xss_dbs = read_dbs_dataset(\"/home/pablo/tesis/tsm-pipeline/experiments/datasets/xss_1.txt\")\n",
    "len(xss_dbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ba229de-69b0-4c39-af3b-315d5cf26572",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xss_sample_100 = rand.choice(xss_dbs, size=70, replace=False)\n",
    "xss_sample_20 = list(set(xss_dbs) - set(xss_sample_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d0e8379-4dfd-4783-b872-9ef197aff782",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:experiments.all:train_and_evaluate with train size 70, test size 20\n",
      "INFO:experiments.all:Running training\n",
      "INFO:scripts.docker:creating /home/pablo/dev-results/xss-perf-experiment-100-run1 dir. Omitting error if already existing\n",
      "INFO:scripts.docker:creating /tmp/log dir. Omitting error if already existing\n",
      "INFO:scripts.docker:running at container c94ffc3dd29525458529f766f1a4d39d610a414e9c09c552f3814ceb50279e2b. Use `docker logs c94ffc3dd29525458529f766f1a4d39d610a414e9c09c552f3814ceb50279e2b --tail 10 --follow` to follow progress\n",
      "INFO:scripts.docker:running combine scores\n",
      "INFO:misc.combinescores:globbing folder: /home/pablo/dev-results/xss-perf-experiment-100-run1/*/reprScores.txt\n",
      "INFO:misc.combinescores:working on 42 reprScores files\n",
      "INFO:experiments.all:Running worse evaluation\n",
      "INFO:scripts.evaluate:creating /home/pablo/dev-results/xss-perf-experiment-100-run1/worse dir. Omitting error if already existing\n",
      "INFO:scripts.evaluate:Starting processing with 4 processes\n",
      "INFO:scripts.evaluate:Evaluating LivePersonInc - engage.liveperson\n",
      "INFO:scripts.evaluate:Evaluating SkypLabs - git-slideshow\n",
      "INFO:scripts.evaluate:Evaluating UtrechtUniversity - yoda-portal-research\n",
      "INFO:scripts.evaluate:Evaluating SteamDatabase - SteamTracking\n",
      "INFO:scripts.evaluate:Evaluating Radhee - spiffcode\n",
      "INFO:scripts.evaluate:Evaluating Breeze - breeze.js.samples\n",
      "INFO:scripts.evaluate:Evaluating StephenGrider - ReactSSRCasts\n",
      "INFO:scripts.evaluate:Evaluating bpm - bpm\n",
      "INFO:scripts.evaluate:Evaluating blockstrap - framework\n",
      "INFO:scripts.evaluate:Evaluating KayFelicities - ExperienceBase\n",
      "INFO:scripts.evaluate:Evaluating FullstackAcademy - Study-Saturday-Fullstack\n",
      "INFO:scripts.evaluate:Evaluating cburgdorf - angular-todo-app\n",
      "INFO:scripts.evaluate:Evaluating EmmetBlue - Emmet-Blue-Ui\n",
      "INFO:scripts.evaluate:Evaluating SAP - ui5-automation-framework\n",
      "INFO:scripts.evaluate:Evaluating DimAce74 - Education\n",
      "INFO:scripts.evaluate:Evaluating TalAter - annyang\n",
      "INFO:scripts.evaluate:Evaluating Sean12697 - SlackChat\n",
      "INFO:scripts.evaluate:Evaluating booktype - Booktype\n",
      "INFO:scripts.evaluate:Evaluating CardinalPath - gas\n",
      "INFO:scripts.evaluate:Evaluating Soontao - openui5\n",
      "INFO:experiments.all:Running boosted evaluation\n",
      "INFO:scripts.evaluate:creating /home/pablo/dev-results/xss-perf-experiment-100-run1/boosted dir. Omitting error if already existing\n",
      "INFO:scripts.evaluate:Starting processing with 4 processes\n",
      "INFO:scripts.evaluate:Evaluating SkypLabs - git-slideshow\n",
      "INFO:scripts.evaluate:Evaluating UtrechtUniversity - yoda-portal-research\n",
      "INFO:scripts.evaluate:Evaluating LivePersonInc - engage.liveperson\n",
      "INFO:scripts.evaluate:Evaluating SteamDatabase - SteamTracking\n",
      "INFO:scripts.evaluate:Evaluating Radhee - spiffcode\n",
      "INFO:scripts.evaluate:Evaluating Breeze - breeze.js.samples\n",
      "INFO:scripts.evaluate:Evaluating bpm - bpm\n",
      "INFO:scripts.evaluate:Evaluating StephenGrider - ReactSSRCasts\n",
      "INFO:scripts.evaluate:Evaluating blockstrap - framework\n",
      "INFO:scripts.evaluate:Evaluating KayFelicities - ExperienceBase\n",
      "INFO:scripts.evaluate:Evaluating FullstackAcademy - Study-Saturday-Fullstack\n",
      "INFO:scripts.evaluate:Evaluating cburgdorf - angular-todo-app\n",
      "INFO:scripts.evaluate:Evaluating EmmetBlue - Emmet-Blue-Ui\n",
      "INFO:scripts.evaluate:Evaluating SAP - ui5-automation-framework\n",
      "INFO:scripts.evaluate:Evaluating DimAce74 - Education\n",
      "INFO:scripts.evaluate:Evaluating TalAter - annyang\n",
      "INFO:scripts.evaluate:Evaluating Sean12697 - SlackChat\n",
      "INFO:scripts.evaluate:Evaluating booktype - Booktype\n",
      "INFO:scripts.evaluate:Evaluating CardinalPath - gas\n",
      "INFO:scripts.evaluate:Evaluating Soontao - openui5\n",
      "INFO:experiments.all:Running v0 evaluation\n",
      "INFO:scripts.evaluate:creating /home/pablo/dev-results/xss-perf-experiment-100-run1/v0 dir. Omitting error if already existing\n",
      "INFO:scripts.evaluate:Starting processing with 4 processes\n",
      "INFO:scripts.evaluate:Evaluating bpm - bpm\n",
      "INFO:scripts.evaluate:Evaluating Radhee - spiffcode\n",
      "INFO:scripts.evaluate:Evaluating Breeze - breeze.js.samples\n",
      "INFO:scripts.evaluate:Evaluating SteamDatabase - SteamTracking\n",
      "INFO:scripts.evaluate:Evaluating UtrechtUniversity - yoda-portal-research\n",
      "INFO:scripts.evaluate:Evaluating LivePersonInc - engage.liveperson\n",
      "INFO:scripts.evaluate:Evaluating SkypLabs - git-slideshow\n",
      "INFO:scripts.evaluate:Evaluating StephenGrider - ReactSSRCasts\n",
      "INFO:scripts.evaluate:Evaluating blockstrap - framework\n",
      "INFO:scripts.evaluate:Evaluating KayFelicities - ExperienceBase\n",
      "INFO:scripts.evaluate:Evaluating FullstackAcademy - Study-Saturday-Fullstack\n",
      "INFO:scripts.evaluate:Evaluating cburgdorf - angular-todo-app\n",
      "INFO:scripts.evaluate:Evaluating EmmetBlue - Emmet-Blue-Ui\n",
      "INFO:scripts.evaluate:Evaluating SAP - ui5-automation-framework\n",
      "INFO:scripts.evaluate:Evaluating DimAce74 - Education\n",
      "INFO:scripts.evaluate:Evaluating TalAter - annyang\n",
      "INFO:scripts.evaluate:Evaluating Sean12697 - SlackChat\n",
      "INFO:scripts.evaluate:Evaluating booktype - Booktype\n",
      "INFO:scripts.evaluate:Evaluating CardinalPath - gas\n",
      "INFO:scripts.evaluate:Evaluating Soontao - openui5\n"
     ]
    },
    {
     "ename": "CLIError",
     "evalue": "Failed to run query: Compiling query plan for /home/pablo/tesis/tsm-pipeline/tsm-evaluation/tsm-evaluation/src/XssEvaluation.ql.\n[1/1] Found in cache: /home/pablo/tesis/tsm-pipeline/tsm-evaluation/tsm-evaluation/src/XssEvaluation.ql.\nStarting evaluation of thepalbi/tsm-evaluation/src/XssEvaluation.ql.\nOops! A fatal internal error occurred. Details:\ncom.semmle.util.exception.CatastrophicError: An error occurred during the evaluation of GlobalAccessPaths#c651dae5::AccessPath::DominatingPaths::hasDominatingWrite#1#f/1@d1617apf\nCould not load page 0 of BasicBlocks#7fe02f60::Internal::reachableBB#1#f/1@615a8bf4 (e8a50f97h4ja9jubi1h1jtb7tidj0)\nThe RA to evaluate was:\n\n    {3} r1 = JOIN _DataFlow#d6e964f9::DataFlow::Node::asExpr#0#dispred#ff_10#join_rhs_GlobalAccessPaths#c651dae5::Acce__#shared WITH DataFlow#d6e964f9::DataFlow::PropRead#class#f ON FIRST 1 OUTPUT Lhs.1, Lhs.2, Lhs.0\n    {2} r2 = JOIN r1 WITH GlobalAccessPaths#c651dae5::AccessPath::DominatingPaths::getAWriteBlock#2#fff ON FIRST 2 OUTPUT Rhs.2, Lhs.2\n    {2} r3 = JOIN r2 WITH boundedFastTC:BasicBlocks#7fe02f60::bbIDominates#2#ff:_DataFlow#d6e964f9::DataFlow::PropRead#class#f_GlobalAccessPaths#c651dae5::AccessPath::DominatingPat__#higher_order_body ON FIRST 1 OUTPUT Rhs.1, Lhs.1\n    {2} r4 = JOIN r3 WITH BasicBlocks#7fe02f60::Internal::reachableBB#1#f ON FIRST 1 OUTPUT Lhs.1, Lhs.0\n    {1} r5 = JOIN r4 WITH DataFlow#d6e964f9::DataFlow::Node::getBasicBlock#0#dispred#ff ON FIRST 2 OUTPUT Lhs.0\n\n    {6} r6 = SCAN GlobalAccessPaths#c651dae5::AccessPath::DominatingPaths::rankedAccessPath#5#ffffff OUTPUT In.4, In.0, In.1, In.2, In.3, In.5\n    {5} r7 = JOIN r6 WITH num#GlobalAccessPaths#c651dae5::AccessPath::DominatingPaths::AccessPathRead#f ON FIRST 1 OUTPUT Lhs.5, Lhs.1, Lhs.2, Lhs.3, Lhs.4\n    {5} r8 = JOIN r7 WITH DataFlow#d6e964f9::DataFlow::Node::asExpr#0#dispred#ff_10#join_rhs ON FIRST 1 OUTPUT Rhs.1, Lhs.1, Lhs.2, Lhs.3, Lhs.4\n    {5} r9 = JOIN r8 WITH DataFlow#d6e964f9::DataFlow::PropRead#class#f ON FIRST 1 OUTPUT Lhs.1, Lhs.2, Lhs.3, Lhs.4, Lhs.0\n    {4} r10 = JOIN r9 WITH project#GlobalAccessPaths#c651dae5::AccessPath::DominatingPaths::rankedAccessPath#5#ffffff ON FIRST 3 OUTPUT Lhs.3, Lhs.4, Rhs.3, Rhs.4\n    {4} r11 = SELECT r10 ON In.2 < In.0\n    {2} r12 = SCAN r11 OUTPUT In.3, In.1\n    {1} r13 = JOIN r12 WITH num#GlobalAccessPaths#c651dae5::AccessPath::DominatingPaths::AccessPathWrite#f ON FIRST 1 OUTPUT Lhs.1\n\n    {3} r14 = JOIN _DataFlow#d6e964f9::DataFlow::Node::asExpr#0#dispred#ff_DataFlow#d6e964f9::DataFlow::PropRead#class#__#shared WITH DataFlow#d6e964f9::DataFlow::PropRef::getPropertyNameExpr#0#dispred#ff ON FIRST 1 OUTPUT Lhs.0, Lhs.1, Rhs.1\n    {4} r15 = JOIN r14 WITH DataFlow#d6e964f9::DataFlow::PropRef::getBase#0#dispred#ff ON FIRST 1 OUTPUT Lhs.2, Lhs.0, Lhs.1, Rhs.1\n    {4} r16 = JOIN r15 WITH project#SSA#077c0ee4::SsaVariable::getAUseIn#1#dispred#fff_10#join_rhs ON FIRST 1 OUTPUT Rhs.1, Lhs.1, Lhs.2, Lhs.3\n    {4} r17 = JOIN r16 WITH project#SSA#077c0ee4::SsaVariable::getAUseIn#1#dispred#fff ON FIRST 1 OUTPUT Rhs.1, Lhs.1, Lhs.2, Lhs.3\n    {4} r18 = JOIN r17 WITH DataFlow#d6e964f9::DataFlow::PropRef::getPropertyNameExpr#0#dispred#ff_10#join_rhs ON FIRST 1 OUTPUT Rhs.1, Lhs.1, Lhs.2, Lhs.3\n    {5} r19 = JOIN r18 WITH DataFlow#d6e964f9::DataFlow::PropWrite::getWriteNode#0#dispred#ff ON FIRST 1 OUTPUT Lhs.0, Lhs.1, Lhs.2, Lhs.3, Rhs.1\n    {5} r20 = JOIN r19 WITH Sources#be5e9acb::SourceNode::getAPropertyWrite#0#dispred#ff_10#join_rhs ON FIRST 1 OUTPUT Lhs.3, Rhs.1, Lhs.1, Lhs.2, Lhs.4\n    {3} r21 = JOIN r20 WITH Sources#be5e9acb::Cached::hasLocalSource#2#ff ON FIRST 2 OUTPUT Lhs.4, Lhs.2, Lhs.3\n    {4} r22 = JOIN r21 WITH BasicBlocks#7fe02f60::Internal::bbIndex#3#fff_102#join_rhs ON FIRST 1 OUTPUT Rhs.1, Lhs.2, Lhs.1, Rhs.2\n    {3} r23 = JOIN r22 WITH BasicBlocks#7fe02f60::Internal::bbIndex#3#fff ON FIRST 2 OUTPUT Lhs.2, Lhs.3, Rhs.2\n    {3} r24 = SELECT r23 ON In.1 < In.2\n    {1} r25 = SCAN r24 OUTPUT In.0\n\n    {1} r26 = r13 UNION r25\n    {1} r27 = r5 UNION r26\n    return r27\n\n(eventual cause: CatastrophicError \"Could not load page 0 of BasicBlocks#7fe02f60::Internal::reachableBB#1#f/1@615a8...\")\n\tat com.semmle.inmemory.pipeline.PipelineInstance.exceptionCaught(PipelineInstance.java:162)\n\tat com.semmle.inmemory.scheduler.execution.ThreadableWork.handleAndLog(ThreadableWork.java:549)\n\tat com.semmle.inmemory.scheduler.execution.ThreadableWork.doSomeWork(ThreadableWork.java:373)\n\tat com.semmle.inmemory.scheduler.IntensionalLayer$IntensionalWork.evaluate(IntensionalLayer.java:73)\n\tat com.semmle.inmemory.scheduler.SimpleLayerTask$SimpleLayerWork.doWork(SimpleLayerTask.java:69)\n\tat com.semmle.inmemory.scheduler.execution.ThreadableWork.doSomeWork(ThreadableWork.java:359)\n\tat com.semmle.inmemory.scheduler.execution.ExecutionScheduler.runnerMain(ExecutionScheduler.java:562)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n\tat java.base/java.lang.Thread.run(Unknown Source)\nCaused by: com.semmle.util.exception.CatastrophicError: Could not load page 0 of BasicBlocks#7fe02f60::Internal::reachableBB#1#f/1@615a8bf4 (e8a50f97h4ja9jubi1h1jtb7tidj0)\n\tat com.semmle.inmemory.caching.PagedRelation.getPage(PagedRelation.java:94)\n\tat com.semmle.inmemory.relations.IntArrayMatcher.switchPageTo(IntArrayMatcher.java:151)\n\tat com.semmle.inmemory.relations.IntArrayMatcher.startMatching(IntArrayMatcher.java:624)\n\tat com.semmle.inmemory.relations.IntArrayMatcher.startBatchJoin(IntArrayMatcher.java:724)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.addBatch(JoinStep.java:75)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverBorrowedBatch(SimpleStep.java:91)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverOwnBatch(SimpleStep.java:79)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.processMidBatch(JoinStep.java:86)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.addBatch(JoinStep.java:77)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverBorrowedBatch(SimpleStep.java:91)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverOwnBatch(SimpleStep.java:79)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.processMidBatch(JoinStep.java:86)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.addBatch(JoinStep.java:77)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverBorrowedBatch(SimpleStep.java:91)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverOwnBatch(SimpleStep.java:79)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.processMidBatch(JoinStep.java:86)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.addBatch(JoinStep.java:77)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverBorrowedBatch(SimpleStep.java:91)\n\tat com.semmle.inmemory.relations.TupleBatch.startNewTuple(TupleBatch.java:233)\n\tat com.semmle.inmemory.relations.Compact.uncompact(Compact.java:114)\n\tat com.semmle.inmemory.relations.cbtree.Matcher.batchedMap(Matcher.java:440)\n\tat com.semmle.inmemory.relations.cbtree.BaseCBTreeRelation.batchedMap(BaseCBTreeRelation.java:83)\n\tat com.semmle.inmemory.caching.PagedRelation.batchedMap(PagedRelation.java:166)\n\tat com.semmle.inmemory.pipeline.LiteralStep.deliverRelation(LiteralStep.java:97)\n\tat com.semmle.inmemory.pipeline.LiteralStep.lambda$collectActions$0(LiteralStep.java:92)\n\tat com.semmle.inmemory.pipeline.HeadEndDispatcher.headEndWork(HeadEndDispatcher.java:78)\n\tat com.semmle.inmemory.pipeline.PipelineState.doSomeWork(PipelineState.java:51)\n\tat com.semmle.inmemory.pipeline.PipelineInstance.doWork(PipelineInstance.java:117)\n\tat com.semmle.inmemory.scheduler.execution.ThreadableWork.doSomeWork(ThreadableWork.java:359)\n\t... 7 more\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/pablo/tesis/tsm-pipeline/code/utils/process.py\", line 24, in run_process\n    proc = subprocess.run(\n  File \"/usr/lib/python3.10/subprocess.py\", line 524, in run\n    raise CalledProcessError(retcode, process.args,\nsubprocess.CalledProcessError: Command '['/home/pablo/clis/codeqlcli-v2.13.1/codeql query run --threads=4 --ram=3512 -d /home/pablo/dbcache/2.5.2/SteamDatabase/SteamTracking/0b88313 --search-path=/home/pablo/codeqlv0/javascript/ql/lib --output=/home/pablo/dev-results/xss-perf-experiment-100-run1/v0/SteamDatabase_SteamTracking_0b88313.bqrs /home/pablo/tesis/tsm-pipeline/tsm-evaluation/tsm-evaluation/src/XssEvaluation.ql']' returned non-zero exit status 100.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/pablo/tesis/tsm-pipeline/code/clients/cli.py\", line 55, in query_run\n    run_process(query_cmd, cwd=self._cwd)\n  File \"/home/pablo/tesis/tsm-pipeline/code/utils/process.py\", line 28, in run_process\n    raise RunProcessError(\nutils.process.RunProcessError: Failed to execute: ['/home/pablo/clis/codeqlcli-v2.13.1/codeql query run --threads=4 --ram=3512 -d /home/pablo/dbcache/2.5.2/SteamDatabase/SteamTracking/0b88313 --search-path=/home/pablo/codeqlv0/javascript/ql/lib --output=/home/pablo/dev-results/xss-perf-experiment-100-run1/v0/SteamDatabase_SteamTracking_0b88313.bqrs /home/pablo/tesis/tsm-pipeline/tsm-evaluation/tsm-evaluation/src/XssEvaluation.ql']\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/home/pablo/tesis/tsm-pipeline/code/scripts/evaluate.py\", line 67, in do_evalute\n    e.evalute()\n  File \"/home/pablo/tesis/tsm-pipeline/code/scripts/evaluate.py\", line 61, in evalute\n    self.client.query_run(self.db, self.settings.search_path, bqrs_out,\n  File \"/home/pablo/tesis/tsm-pipeline/code/clients/cli.py\", line 57, in query_run\n    raise CLIError(\"Failed to run query: %s\" % (err.stderr))\nclients.cli.CLIError: Failed to run query: Compiling query plan for /home/pablo/tesis/tsm-pipeline/tsm-evaluation/tsm-evaluation/src/XssEvaluation.ql.\n[1/1] Found in cache: /home/pablo/tesis/tsm-pipeline/tsm-evaluation/tsm-evaluation/src/XssEvaluation.ql.\nStarting evaluation of thepalbi/tsm-evaluation/src/XssEvaluation.ql.\nOops! A fatal internal error occurred. Details:\ncom.semmle.util.exception.CatastrophicError: An error occurred during the evaluation of GlobalAccessPaths#c651dae5::AccessPath::DominatingPaths::hasDominatingWrite#1#f/1@d1617apf\nCould not load page 0 of BasicBlocks#7fe02f60::Internal::reachableBB#1#f/1@615a8bf4 (e8a50f97h4ja9jubi1h1jtb7tidj0)\nThe RA to evaluate was:\n\n    {3} r1 = JOIN _DataFlow#d6e964f9::DataFlow::Node::asExpr#0#dispred#ff_10#join_rhs_GlobalAccessPaths#c651dae5::Acce__#shared WITH DataFlow#d6e964f9::DataFlow::PropRead#class#f ON FIRST 1 OUTPUT Lhs.1, Lhs.2, Lhs.0\n    {2} r2 = JOIN r1 WITH GlobalAccessPaths#c651dae5::AccessPath::DominatingPaths::getAWriteBlock#2#fff ON FIRST 2 OUTPUT Rhs.2, Lhs.2\n    {2} r3 = JOIN r2 WITH boundedFastTC:BasicBlocks#7fe02f60::bbIDominates#2#ff:_DataFlow#d6e964f9::DataFlow::PropRead#class#f_GlobalAccessPaths#c651dae5::AccessPath::DominatingPat__#higher_order_body ON FIRST 1 OUTPUT Rhs.1, Lhs.1\n    {2} r4 = JOIN r3 WITH BasicBlocks#7fe02f60::Internal::reachableBB#1#f ON FIRST 1 OUTPUT Lhs.1, Lhs.0\n    {1} r5 = JOIN r4 WITH DataFlow#d6e964f9::DataFlow::Node::getBasicBlock#0#dispred#ff ON FIRST 2 OUTPUT Lhs.0\n\n    {6} r6 = SCAN GlobalAccessPaths#c651dae5::AccessPath::DominatingPaths::rankedAccessPath#5#ffffff OUTPUT In.4, In.0, In.1, In.2, In.3, In.5\n    {5} r7 = JOIN r6 WITH num#GlobalAccessPaths#c651dae5::AccessPath::DominatingPaths::AccessPathRead#f ON FIRST 1 OUTPUT Lhs.5, Lhs.1, Lhs.2, Lhs.3, Lhs.4\n    {5} r8 = JOIN r7 WITH DataFlow#d6e964f9::DataFlow::Node::asExpr#0#dispred#ff_10#join_rhs ON FIRST 1 OUTPUT Rhs.1, Lhs.1, Lhs.2, Lhs.3, Lhs.4\n    {5} r9 = JOIN r8 WITH DataFlow#d6e964f9::DataFlow::PropRead#class#f ON FIRST 1 OUTPUT Lhs.1, Lhs.2, Lhs.3, Lhs.4, Lhs.0\n    {4} r10 = JOIN r9 WITH project#GlobalAccessPaths#c651dae5::AccessPath::DominatingPaths::rankedAccessPath#5#ffffff ON FIRST 3 OUTPUT Lhs.3, Lhs.4, Rhs.3, Rhs.4\n    {4} r11 = SELECT r10 ON In.2 < In.0\n    {2} r12 = SCAN r11 OUTPUT In.3, In.1\n    {1} r13 = JOIN r12 WITH num#GlobalAccessPaths#c651dae5::AccessPath::DominatingPaths::AccessPathWrite#f ON FIRST 1 OUTPUT Lhs.1\n\n    {3} r14 = JOIN _DataFlow#d6e964f9::DataFlow::Node::asExpr#0#dispred#ff_DataFlow#d6e964f9::DataFlow::PropRead#class#__#shared WITH DataFlow#d6e964f9::DataFlow::PropRef::getPropertyNameExpr#0#dispred#ff ON FIRST 1 OUTPUT Lhs.0, Lhs.1, Rhs.1\n    {4} r15 = JOIN r14 WITH DataFlow#d6e964f9::DataFlow::PropRef::getBase#0#dispred#ff ON FIRST 1 OUTPUT Lhs.2, Lhs.0, Lhs.1, Rhs.1\n    {4} r16 = JOIN r15 WITH project#SSA#077c0ee4::SsaVariable::getAUseIn#1#dispred#fff_10#join_rhs ON FIRST 1 OUTPUT Rhs.1, Lhs.1, Lhs.2, Lhs.3\n    {4} r17 = JOIN r16 WITH project#SSA#077c0ee4::SsaVariable::getAUseIn#1#dispred#fff ON FIRST 1 OUTPUT Rhs.1, Lhs.1, Lhs.2, Lhs.3\n    {4} r18 = JOIN r17 WITH DataFlow#d6e964f9::DataFlow::PropRef::getPropertyNameExpr#0#dispred#ff_10#join_rhs ON FIRST 1 OUTPUT Rhs.1, Lhs.1, Lhs.2, Lhs.3\n    {5} r19 = JOIN r18 WITH DataFlow#d6e964f9::DataFlow::PropWrite::getWriteNode#0#dispred#ff ON FIRST 1 OUTPUT Lhs.0, Lhs.1, Lhs.2, Lhs.3, Rhs.1\n    {5} r20 = JOIN r19 WITH Sources#be5e9acb::SourceNode::getAPropertyWrite#0#dispred#ff_10#join_rhs ON FIRST 1 OUTPUT Lhs.3, Rhs.1, Lhs.1, Lhs.2, Lhs.4\n    {3} r21 = JOIN r20 WITH Sources#be5e9acb::Cached::hasLocalSource#2#ff ON FIRST 2 OUTPUT Lhs.4, Lhs.2, Lhs.3\n    {4} r22 = JOIN r21 WITH BasicBlocks#7fe02f60::Internal::bbIndex#3#fff_102#join_rhs ON FIRST 1 OUTPUT Rhs.1, Lhs.2, Lhs.1, Rhs.2\n    {3} r23 = JOIN r22 WITH BasicBlocks#7fe02f60::Internal::bbIndex#3#fff ON FIRST 2 OUTPUT Lhs.2, Lhs.3, Rhs.2\n    {3} r24 = SELECT r23 ON In.1 < In.2\n    {1} r25 = SCAN r24 OUTPUT In.0\n\n    {1} r26 = r13 UNION r25\n    {1} r27 = r5 UNION r26\n    return r27\n\n(eventual cause: CatastrophicError \"Could not load page 0 of BasicBlocks#7fe02f60::Internal::reachableBB#1#f/1@615a8...\")\n\tat com.semmle.inmemory.pipeline.PipelineInstance.exceptionCaught(PipelineInstance.java:162)\n\tat com.semmle.inmemory.scheduler.execution.ThreadableWork.handleAndLog(ThreadableWork.java:549)\n\tat com.semmle.inmemory.scheduler.execution.ThreadableWork.doSomeWork(ThreadableWork.java:373)\n\tat com.semmle.inmemory.scheduler.IntensionalLayer$IntensionalWork.evaluate(IntensionalLayer.java:73)\n\tat com.semmle.inmemory.scheduler.SimpleLayerTask$SimpleLayerWork.doWork(SimpleLayerTask.java:69)\n\tat com.semmle.inmemory.scheduler.execution.ThreadableWork.doSomeWork(ThreadableWork.java:359)\n\tat com.semmle.inmemory.scheduler.execution.ExecutionScheduler.runnerMain(ExecutionScheduler.java:562)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n\tat java.base/java.lang.Thread.run(Unknown Source)\nCaused by: com.semmle.util.exception.CatastrophicError: Could not load page 0 of BasicBlocks#7fe02f60::Internal::reachableBB#1#f/1@615a8bf4 (e8a50f97h4ja9jubi1h1jtb7tidj0)\n\tat com.semmle.inmemory.caching.PagedRelation.getPage(PagedRelation.java:94)\n\tat com.semmle.inmemory.relations.IntArrayMatcher.switchPageTo(IntArrayMatcher.java:151)\n\tat com.semmle.inmemory.relations.IntArrayMatcher.startMatching(IntArrayMatcher.java:624)\n\tat com.semmle.inmemory.relations.IntArrayMatcher.startBatchJoin(IntArrayMatcher.java:724)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.addBatch(JoinStep.java:75)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverBorrowedBatch(SimpleStep.java:91)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverOwnBatch(SimpleStep.java:79)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.processMidBatch(JoinStep.java:86)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.addBatch(JoinStep.java:77)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverBorrowedBatch(SimpleStep.java:91)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverOwnBatch(SimpleStep.java:79)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.processMidBatch(JoinStep.java:86)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.addBatch(JoinStep.java:77)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverBorrowedBatch(SimpleStep.java:91)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverOwnBatch(SimpleStep.java:79)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.processMidBatch(JoinStep.java:86)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.addBatch(JoinStep.java:77)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverBorrowedBatch(SimpleStep.java:91)\n\tat com.semmle.inmemory.relations.TupleBatch.startNewTuple(TupleBatch.java:233)\n\tat com.semmle.inmemory.relations.Compact.uncompact(Compact.java:114)\n\tat com.semmle.inmemory.relations.cbtree.Matcher.batchedMap(Matcher.java:440)\n\tat com.semmle.inmemory.relations.cbtree.BaseCBTreeRelation.batchedMap(BaseCBTreeRelation.java:83)\n\tat com.semmle.inmemory.caching.PagedRelation.batchedMap(PagedRelation.java:166)\n\tat com.semmle.inmemory.pipeline.LiteralStep.deliverRelation(LiteralStep.java:97)\n\tat com.semmle.inmemory.pipeline.LiteralStep.lambda$collectActions$0(LiteralStep.java:92)\n\tat com.semmle.inmemory.pipeline.HeadEndDispatcher.headEndWork(HeadEndDispatcher.java:78)\n\tat com.semmle.inmemory.pipeline.PipelineState.doSomeWork(PipelineState.java:51)\n\tat com.semmle.inmemory.pipeline.PipelineInstance.doWork(PipelineInstance.java:117)\n\tat com.semmle.inmemory.scheduler.execution.ThreadableWork.doSomeWork(ThreadableWork.java:359)\n\t... 7 more\n\n\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mCLIError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m outdir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/pablo/dev-results/xss-perf-experiment-100-run1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresults_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mxss_sample_100\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxss_sample_20\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocker_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocker_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m results\n",
      "File \u001b[0;32m~/tesis/tsm-pipeline/code/experiments/all.py:113\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(config, results_dir, train, test, query_type, docker_client, skip)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluate_v0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m skip:\n\u001b[1;32m    112\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning v0 evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 113\u001b[0m     \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mv0_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_join\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mv0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipping v0 evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/tesis/tsm-pipeline/code/scripts/evaluate.py:114\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(settings, output_dir, dbs_path, dbs)\u001b[0m\n\u001b[1;32m    104\u001b[0m evaluators \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    105\u001b[0m     Evaluator(\n\u001b[1;32m    106\u001b[0m         settings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m     ) \u001b[38;5;28;01mfor\u001b[39;00m (pk, db) \u001b[38;5;129;01min\u001b[39;00m dbs_from_cache\n\u001b[1;32m    112\u001b[0m ]\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39msettings\u001b[38;5;241m.\u001b[39mperformance\u001b[38;5;241m.\u001b[39mparallelism) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m--> 114\u001b[0m     \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo_evalute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mCLIError\u001b[0m: Failed to run query: Compiling query plan for /home/pablo/tesis/tsm-pipeline/tsm-evaluation/tsm-evaluation/src/XssEvaluation.ql.\n[1/1] Found in cache: /home/pablo/tesis/tsm-pipeline/tsm-evaluation/tsm-evaluation/src/XssEvaluation.ql.\nStarting evaluation of thepalbi/tsm-evaluation/src/XssEvaluation.ql.\nOops! A fatal internal error occurred. Details:\ncom.semmle.util.exception.CatastrophicError: An error occurred during the evaluation of GlobalAccessPaths#c651dae5::AccessPath::DominatingPaths::hasDominatingWrite#1#f/1@d1617apf\nCould not load page 0 of BasicBlocks#7fe02f60::Internal::reachableBB#1#f/1@615a8bf4 (e8a50f97h4ja9jubi1h1jtb7tidj0)\nThe RA to evaluate was:\n\n    {3} r1 = JOIN _DataFlow#d6e964f9::DataFlow::Node::asExpr#0#dispred#ff_10#join_rhs_GlobalAccessPaths#c651dae5::Acce__#shared WITH DataFlow#d6e964f9::DataFlow::PropRead#class#f ON FIRST 1 OUTPUT Lhs.1, Lhs.2, Lhs.0\n    {2} r2 = JOIN r1 WITH GlobalAccessPaths#c651dae5::AccessPath::DominatingPaths::getAWriteBlock#2#fff ON FIRST 2 OUTPUT Rhs.2, Lhs.2\n    {2} r3 = JOIN r2 WITH boundedFastTC:BasicBlocks#7fe02f60::bbIDominates#2#ff:_DataFlow#d6e964f9::DataFlow::PropRead#class#f_GlobalAccessPaths#c651dae5::AccessPath::DominatingPat__#higher_order_body ON FIRST 1 OUTPUT Rhs.1, Lhs.1\n    {2} r4 = JOIN r3 WITH BasicBlocks#7fe02f60::Internal::reachableBB#1#f ON FIRST 1 OUTPUT Lhs.1, Lhs.0\n    {1} r5 = JOIN r4 WITH DataFlow#d6e964f9::DataFlow::Node::getBasicBlock#0#dispred#ff ON FIRST 2 OUTPUT Lhs.0\n\n    {6} r6 = SCAN GlobalAccessPaths#c651dae5::AccessPath::DominatingPaths::rankedAccessPath#5#ffffff OUTPUT In.4, In.0, In.1, In.2, In.3, In.5\n    {5} r7 = JOIN r6 WITH num#GlobalAccessPaths#c651dae5::AccessPath::DominatingPaths::AccessPathRead#f ON FIRST 1 OUTPUT Lhs.5, Lhs.1, Lhs.2, Lhs.3, Lhs.4\n    {5} r8 = JOIN r7 WITH DataFlow#d6e964f9::DataFlow::Node::asExpr#0#dispred#ff_10#join_rhs ON FIRST 1 OUTPUT Rhs.1, Lhs.1, Lhs.2, Lhs.3, Lhs.4\n    {5} r9 = JOIN r8 WITH DataFlow#d6e964f9::DataFlow::PropRead#class#f ON FIRST 1 OUTPUT Lhs.1, Lhs.2, Lhs.3, Lhs.4, Lhs.0\n    {4} r10 = JOIN r9 WITH project#GlobalAccessPaths#c651dae5::AccessPath::DominatingPaths::rankedAccessPath#5#ffffff ON FIRST 3 OUTPUT Lhs.3, Lhs.4, Rhs.3, Rhs.4\n    {4} r11 = SELECT r10 ON In.2 < In.0\n    {2} r12 = SCAN r11 OUTPUT In.3, In.1\n    {1} r13 = JOIN r12 WITH num#GlobalAccessPaths#c651dae5::AccessPath::DominatingPaths::AccessPathWrite#f ON FIRST 1 OUTPUT Lhs.1\n\n    {3} r14 = JOIN _DataFlow#d6e964f9::DataFlow::Node::asExpr#0#dispred#ff_DataFlow#d6e964f9::DataFlow::PropRead#class#__#shared WITH DataFlow#d6e964f9::DataFlow::PropRef::getPropertyNameExpr#0#dispred#ff ON FIRST 1 OUTPUT Lhs.0, Lhs.1, Rhs.1\n    {4} r15 = JOIN r14 WITH DataFlow#d6e964f9::DataFlow::PropRef::getBase#0#dispred#ff ON FIRST 1 OUTPUT Lhs.2, Lhs.0, Lhs.1, Rhs.1\n    {4} r16 = JOIN r15 WITH project#SSA#077c0ee4::SsaVariable::getAUseIn#1#dispred#fff_10#join_rhs ON FIRST 1 OUTPUT Rhs.1, Lhs.1, Lhs.2, Lhs.3\n    {4} r17 = JOIN r16 WITH project#SSA#077c0ee4::SsaVariable::getAUseIn#1#dispred#fff ON FIRST 1 OUTPUT Rhs.1, Lhs.1, Lhs.2, Lhs.3\n    {4} r18 = JOIN r17 WITH DataFlow#d6e964f9::DataFlow::PropRef::getPropertyNameExpr#0#dispred#ff_10#join_rhs ON FIRST 1 OUTPUT Rhs.1, Lhs.1, Lhs.2, Lhs.3\n    {5} r19 = JOIN r18 WITH DataFlow#d6e964f9::DataFlow::PropWrite::getWriteNode#0#dispred#ff ON FIRST 1 OUTPUT Lhs.0, Lhs.1, Lhs.2, Lhs.3, Rhs.1\n    {5} r20 = JOIN r19 WITH Sources#be5e9acb::SourceNode::getAPropertyWrite#0#dispred#ff_10#join_rhs ON FIRST 1 OUTPUT Lhs.3, Rhs.1, Lhs.1, Lhs.2, Lhs.4\n    {3} r21 = JOIN r20 WITH Sources#be5e9acb::Cached::hasLocalSource#2#ff ON FIRST 2 OUTPUT Lhs.4, Lhs.2, Lhs.3\n    {4} r22 = JOIN r21 WITH BasicBlocks#7fe02f60::Internal::bbIndex#3#fff_102#join_rhs ON FIRST 1 OUTPUT Rhs.1, Lhs.2, Lhs.1, Rhs.2\n    {3} r23 = JOIN r22 WITH BasicBlocks#7fe02f60::Internal::bbIndex#3#fff ON FIRST 2 OUTPUT Lhs.2, Lhs.3, Rhs.2\n    {3} r24 = SELECT r23 ON In.1 < In.2\n    {1} r25 = SCAN r24 OUTPUT In.0\n\n    {1} r26 = r13 UNION r25\n    {1} r27 = r5 UNION r26\n    return r27\n\n(eventual cause: CatastrophicError \"Could not load page 0 of BasicBlocks#7fe02f60::Internal::reachableBB#1#f/1@615a8...\")\n\tat com.semmle.inmemory.pipeline.PipelineInstance.exceptionCaught(PipelineInstance.java:162)\n\tat com.semmle.inmemory.scheduler.execution.ThreadableWork.handleAndLog(ThreadableWork.java:549)\n\tat com.semmle.inmemory.scheduler.execution.ThreadableWork.doSomeWork(ThreadableWork.java:373)\n\tat com.semmle.inmemory.scheduler.IntensionalLayer$IntensionalWork.evaluate(IntensionalLayer.java:73)\n\tat com.semmle.inmemory.scheduler.SimpleLayerTask$SimpleLayerWork.doWork(SimpleLayerTask.java:69)\n\tat com.semmle.inmemory.scheduler.execution.ThreadableWork.doSomeWork(ThreadableWork.java:359)\n\tat com.semmle.inmemory.scheduler.execution.ExecutionScheduler.runnerMain(ExecutionScheduler.java:562)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n\tat java.base/java.lang.Thread.run(Unknown Source)\nCaused by: com.semmle.util.exception.CatastrophicError: Could not load page 0 of BasicBlocks#7fe02f60::Internal::reachableBB#1#f/1@615a8bf4 (e8a50f97h4ja9jubi1h1jtb7tidj0)\n\tat com.semmle.inmemory.caching.PagedRelation.getPage(PagedRelation.java:94)\n\tat com.semmle.inmemory.relations.IntArrayMatcher.switchPageTo(IntArrayMatcher.java:151)\n\tat com.semmle.inmemory.relations.IntArrayMatcher.startMatching(IntArrayMatcher.java:624)\n\tat com.semmle.inmemory.relations.IntArrayMatcher.startBatchJoin(IntArrayMatcher.java:724)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.addBatch(JoinStep.java:75)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverBorrowedBatch(SimpleStep.java:91)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverOwnBatch(SimpleStep.java:79)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.processMidBatch(JoinStep.java:86)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.addBatch(JoinStep.java:77)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverBorrowedBatch(SimpleStep.java:91)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverOwnBatch(SimpleStep.java:79)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.processMidBatch(JoinStep.java:86)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.addBatch(JoinStep.java:77)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverBorrowedBatch(SimpleStep.java:91)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverOwnBatch(SimpleStep.java:79)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.processMidBatch(JoinStep.java:86)\n\tat com.semmle.inmemory.pipeline.JoinStep$JoinState.addBatch(JoinStep.java:77)\n\tat com.semmle.inmemory.pipeline.SimpleStep$SimpleState.deliverBorrowedBatch(SimpleStep.java:91)\n\tat com.semmle.inmemory.relations.TupleBatch.startNewTuple(TupleBatch.java:233)\n\tat com.semmle.inmemory.relations.Compact.uncompact(Compact.java:114)\n\tat com.semmle.inmemory.relations.cbtree.Matcher.batchedMap(Matcher.java:440)\n\tat com.semmle.inmemory.relations.cbtree.BaseCBTreeRelation.batchedMap(BaseCBTreeRelation.java:83)\n\tat com.semmle.inmemory.caching.PagedRelation.batchedMap(PagedRelation.java:166)\n\tat com.semmle.inmemory.pipeline.LiteralStep.deliverRelation(LiteralStep.java:97)\n\tat com.semmle.inmemory.pipeline.LiteralStep.lambda$collectActions$0(LiteralStep.java:92)\n\tat com.semmle.inmemory.pipeline.HeadEndDispatcher.headEndWork(HeadEndDispatcher.java:78)\n\tat com.semmle.inmemory.pipeline.PipelineState.doSomeWork(PipelineState.java:51)\n\tat com.semmle.inmemory.pipeline.PipelineInstance.doWork(PipelineInstance.java:117)\n\tat com.semmle.inmemory.scheduler.execution.ThreadableWork.doSomeWork(ThreadableWork.java:359)\n\t... 7 more\n\n"
     ]
    }
   ],
   "source": [
    "outdir = \"/home/pablo/dev-results/xss-perf-experiment-100-run1\"\n",
    "\n",
    "results = train_and_evaluate(\n",
    "    config=config,\n",
    "    results_dir=outdir,\n",
    "    query_type=\"xss\",\n",
    "    train=list(xss_sample_100),\n",
    "    test=xss_sample_20,\n",
    "    docker_client=docker_client,\n",
    ")\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
